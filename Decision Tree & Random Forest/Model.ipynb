{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Importing the necessary libraries\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import xlogy\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Remove all the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set env CUDA_LAUNCH_BLOCKING=1\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utility functions for the Model\n",
    "\"\"\"\n",
    "\n",
    "def entropy(Y: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Y: pd.Series: Output values\n",
    "\n",
    "    Returns: float: Entropy\n",
    "    \"\"\"\n",
    "\n",
    "    vals = Y.value_counts(normalize=True)\n",
    "    return -np.sum(xlogy(vals, vals))\n",
    "\n",
    "def gini_index(Y: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Y: pd.Series: Output values\n",
    "\n",
    "    Returns: float: Gini Index\n",
    "    \"\"\"\n",
    "\n",
    "    vals = Y.value_counts(normalize=True)\n",
    "    return 1 - np.sum(np.square(vals))\n",
    "\n",
    "def information_gain(parent: pd.Series, left: pd.Series, right: pd.Series):\n",
    "    \"\"\"\n",
    "    parent: pd.Series: Input parent dataset.\n",
    "    left: pd.Series: Subset of the parent dataset.\n",
    "    right: pd.Series: Subset of the parent dataset.\n",
    "\n",
    "    Returns: float: Information gain.\n",
    "    \"\"\"\n",
    "\n",
    "    # calculate parent and child entropy\n",
    "    before_entropy = entropy(parent)\n",
    "    after_entropy = (len(left) / len(parent)) * entropy(left) + (len(right) / len(parent)) * entropy(right)\n",
    "        \n",
    "    # calculate information gain \n",
    "    information_gain = before_entropy - after_entropy\n",
    "    return information_gain\n",
    "\n",
    "def best_split(dataset: pd.DataFrame, num_samples: int, num_features: int):\n",
    "    \"\"\"\n",
    "    dataset: pd.DataFrame: The dataset to split.\n",
    "    num_samples: int: The number of samples in the dataset.\n",
    "    num_features: int: The number of features in the dataset.\n",
    "\n",
    "    Returns: dict: A dictionary with the best split.\n",
    "    \"\"\"\n",
    "        \n",
    "    # Find the best split\n",
    "    best_split = {'gain':- 1, 'feature': None, 'threshold': None, \"left_dataset\": None, \"right_dataset\": None, \"gain\": None}\n",
    "    for feature_index in range(num_features):\n",
    "        feature_values = dataset.iloc[:, feature_index]\n",
    "        thresholds = np.unique(feature_values)\n",
    "        for threshold in thresholds:\n",
    "            left_dataset, right_dataset = split_data(dataset, feature_index, threshold)\n",
    "            y, left_y, right_y = dataset.iloc[:, -1], left_dataset.iloc[:, -1], right_dataset.iloc[:, -1]\n",
    "            gain = information_gain(y, left_y, right_y)\n",
    "            if gain > best_split[\"gain\"]:\n",
    "                best_split[\"feature\"] = feature_index\n",
    "                best_split[\"threshold\"] = threshold\n",
    "                best_split[\"left_dataset\"] = left_dataset\n",
    "                best_split[\"right_dataset\"] = right_dataset\n",
    "                best_split[\"gain\"] = gain\n",
    "    return best_split\n",
    "\n",
    "def split_data(dataset: pd.DataFrame, feature: int, threshold: float):\n",
    "    \"\"\"\n",
    "    dataset: pd.DataFrame: Input dataset.\n",
    "    feature: int: Index of the feature to be split on.\n",
    "    threshold: float: Threshold value to split the feature on.\n",
    "\n",
    "    Returns:\n",
    "        left_dataset: pd.DataFrame: Subset of the dataset.\n",
    "        right_dataset: pd.DataFrame: Subset of the dataset.\n",
    "    \"\"\"\n",
    "    # Create mask of the dataset using threshold\n",
    "    mask = (dataset.iloc[:, feature] <= threshold)\n",
    "\n",
    "    # Mask the dataset\n",
    "    left_dataset = dataset[mask]\n",
    "    right_dataset = dataset[~mask]\n",
    "    return left_dataset, right_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n",
      "Size of the dataset:  (150, 5)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Convert to DataFrame\n",
    "dataset = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "dataset['target'] = iris.target\n",
    "\n",
    "# Print the first few records\n",
    "print(dataset.head())\n",
    "\n",
    "# Print the size of the dataset\n",
    "print(\"Size of the dataset: \", dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Dataset:\n",
      "[[0.80377277 0.55160877 0.22064351 0.0315205 ]\n",
      " [0.82813288 0.50702012 0.23660939 0.03380134]\n",
      " [0.80533306 0.5483119  0.2227517  0.03426949]\n",
      " [0.80003025 0.53915081 0.26087943 0.03478393]\n",
      " [0.790965   0.56949479 0.2214702  0.0316386 ]]\n",
      "\n",
      "Target Dataset:\n",
      "tensor([0, 0, 0, 0, 0])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert the dataset to a tensor\n",
    "X = torch.tensor(dataset.iloc[:, :-1].values, dtype=torch.float32)\n",
    "Y = torch.tensor(dataset.iloc[:, -1].values, dtype=torch.int64)\n",
    "\n",
    "# Normalize the dataset\n",
    "X = preprocessing.normalize(X)\n",
    "\n",
    "# Print the first few records\n",
    "print(f'Feature Dataset:\\n{X[:5]}\\n')\n",
    "print(f'Target Dataset:\\n{Y[:5]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    \"\"\"\n",
    "    A class representing a node in a decision tree.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, gain=None, value=None):\n",
    "        \"\"\"\n",
    "        feature: string: The feature used for splitting at this node.\n",
    "        threshold: List of float: The threshold used for splitting at this node.\n",
    "        left: Node: Pointer to the left Node.\n",
    "        Right: Node: Pointer to the Right Node.\n",
    "        gain: float: The gain of the split.\n",
    "        value: float: predicted value at this node.\n",
    "        \"\"\"\n",
    "\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.gain = gain\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    \"\"\"\n",
    "    A decision tree classifier.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, min_samples=2, max_depth=2):\n",
    "        \"\"\"\n",
    "        Constructor for DecisionTree class.\n",
    "\n",
    "        min_samples: int: Minimum number of samples at leaf node.\n",
    "        max_depth: int: Maximum depth of the decision tree.\n",
    "        \"\"\"\n",
    "        self.min_samples = min_samples\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def build_tree(self, dataset: pd.DataFrame, current_depth=0):\n",
    "        \"\"\"\n",
    "        dataset: pd.DataFrame: The dataset to build the tree.\n",
    "        current_depth: int: The current depth of the tree.\n",
    "\n",
    "        Returns: Node: The root node of the decision tree.\n",
    "        \"\"\"\n",
    "        \n",
    "        # split the dataset into X, y values\n",
    "        X, y = dataset.iloc[:, :-1], dataset.iloc[:, -1]\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Terminating conditions\n",
    "        if n_samples >= self.min_samples and current_depth <= self.max_depth:\n",
    "            best_split_values = best_split(dataset, n_samples, n_features)\n",
    "            left_node = self.build_tree(best_split_values[\"left_dataset\"], current_depth + 1)\n",
    "            right_node = self.build_tree(best_split_values[\"right_dataset\"], current_depth + 1)\n",
    "\n",
    "            return Node(best_split_values[\"feature\"], best_split_values[\"threshold\"], left_node, right_node, best_split_values[\"gain\"])\n",
    "\n",
    "        # compute leaf node value\n",
    "        leaf_value = y.mode()[0]\n",
    "        return Node(value=leaf_value)\n",
    "    \n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
    "        \"\"\"\n",
    "        X: pd.DataFrame: The feature datset.\n",
    "        y: pd.Series: The target values.\n",
    "        \"\"\"\n",
    "        \n",
    "        dataset = pd.concat([X, y], axis=1) \n",
    "        self.root = self.build_tree(dataset)\n",
    "\n",
    "    def predict(self, X: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        X: pd.DataFrame: The feature matrix to make predictions for.\n",
    "\n",
    "        Returns:\n",
    "        list: A list of predicted class labels.\n",
    "        \"\"\"\n",
    "        \n",
    "        predictions = X.apply(self.traverse_tree, axis=1, args=(self.root,))\n",
    "        return predictions\n",
    "    \n",
    "    def traverse_tree(self, X: pd.Series, node: Node):\n",
    "        \"\"\"\n",
    "        X: pd.Series: The feature vector to predict the target value for.\n",
    "        node: Node: The current node being evaluated.\n",
    "\n",
    "        Returns: float: The predicted target value.\n",
    "        \"\"\"\n",
    "        \n",
    "        if node.value != None: # if the node is a leaf node\n",
    "            return node.value\n",
    "        else: # if the node is not a leaf node\n",
    "            feature = X.iloc[node.feature]\n",
    "            if feature <= node.threshold:\n",
    "                return self.traverse_tree(X, node.left)\n",
    "            else:\n",
    "                return self.traverse_tree(X, node.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
